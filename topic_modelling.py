#

'''
Groups tweets with the same topic together.

NOTE: the BTM algorithm needs to be run first such that it's output can be used
here

Process:
1. Combine BTM Topic modelling outputs and tweet corpus
2. Group tweet corpus together according to the highest probable topic that they
are in

What to do with the data / Next steps after running this code:
- Need to compare topics identified in the BTM terminal output with this output
(note that the columns get sorted according to the highest probable topic in
this code, just like with the BTM output). The sorted probabilities are also
saved in a csv for cross-referencing.

'''
import pandas as pd
import numpy as np
# plotting
from collections import Counter
import matplotlib.pyplot as plt


def run():
    '''
    Main running code that executes all topic modelling functions in the
    correct order for the pipeline.
    '''
    print("Applying topic modelling to BTM output and cleaned corpus...")

    confusion_matrix, topic_probabilities, tweet_corpus = load_data()

    # sort confusion matrix according to highest topic probability
    df = confusion_matrix.T
    df['probs'] = topic_probabilities
    df = df.sort_values(by='probs', ascending=False).T

    # rename columns from 1-k (K being the number of columns)
    mapping = {col_name: i for col_name, i in zip(df.columns, range(20))}
    df = df.rename(mapping, axis=1)

    # add tweet corpus data to the confusion matrix
    df.insert(0, "created_at", tweet_corpus["created_at"])
    df.insert(1, "corpus", tweet_corpus["corpus"])
    df.insert(2, "cleaned_tweet", tweet_corpus["cleaned_tweet"])
    # remove the topic probability row (used to sort the dataframe)
    df = df.drop("probs")

    # group topics and export selected columns to csv
    df = group_topics(df)
    selected_columns = ["maxtopic", "created_at", "corpus", "cleaned_tweet"]
    df.to_csv('datain/sentiment/grouped-by-topic_with_date.csv', columns = selected_columns)

    plot_topic_ratio(df)
    # uncomment to run test
    # run_test()
    print("Finished topic modelling...")


def load_data():
    '''
    Import BTM output (pz_w - confusion_matrix; pz - topic_probabilities) and
    cleaned corpus DataFrame generated by clean_corpus.py.

    @return confusion_matrix, topic_probabilities, tweet_corpus
    '''
    # load confusion matrix (pz_d) BTM output
    confusion_matrix = np.loadtxt("datain/topic_modelling/k20.pz_d")
    confusion_matrix = pd.DataFrame(confusion_matrix)

    # load topic label probabilities (pz) BTM output
    topic_probabilities = np.loadtxt("datain/topic_modelling/k20.pz")

    # load teet corpus data
    tweet_corpus = pd.read_csv("datain/topic_modelling/cleaned_tweets.csv")
    tweet_corpus = tweet_corpus.drop("Unnamed: 0", axis=1)

    return confusion_matrix, topic_probabilities, tweet_corpus

def group_topics(csv):
    '''
    Group topics according to their most probable topic classification according
    to the confusion_matrix.

    @param csv - DataFrame with combined values from confusion_matrix and tweet_corpus
    @return DataFrame grouped/sorted according to their maximum probable topic
    '''
    # get the columns representing the topics
    topics = list(csv.columns[3:])

    # selecting only the columns that denote probabilities for each topic
    maxtopic = csv[topics]
    # get the topic with the max probability value for each row
    maxtopic = maxtopic.idxmax(axis=1)
    # replace all NaN values with 100
    maxtopic = maxtopic.fillna(100)
    # convert all topics from string ('15') to int (15). This prerpares it for grouping by topic
    maxtopic = maxtopic.astype(int)
    # add this as a new column
    csv.insert(0, "maxtopic", maxtopic)

    # group by topic
    return csv.sort_values('maxtopic')

def plot_topic_ratio(csv):
    # count the number of tweets per topic
    topic2occurrences = Counter(csv['maxtopic'])
    topic2occurrences['No Topic'] = topic2occurrences[100]
    del topic2occurrences[100]

    # Plot ratio of tweets per topic
    ys = []
    labels = []
    for topic, occurrences in topic2occurrences.items():
        labels.append(topic)
        ys.append(occurrences)

    plt.pie(ys, labels=labels)
    plt.title('Ratio of tweets per topic')
    plt.savefig('dataout/topic_modelling/topic_ratios.jpeg')
    plt.close()

def run_test():
    # test if prev topic classification is the same as new automated topic classification
    comparison = []
    for topic in range(20):
        comparison.append(test_output(topic))
    # check if all elements in list are True
    print("Topic modelling tests passed: {}".format(all(comparison)))


def test_output(topic_number):
    '''
        Check if previous topic grouping is the same as the automated coding topic grouping
    '''
    prev_topic_grouping = pd.read_csv("test/grouped-by-topic_with_date.csv")
    prev_topic_grouping = sorted(prev_topic_grouping[prev_topic_grouping["maxtopic"] == topic_number]["Topic (Unsorted)"])

    automated_topic_grouping = sorted(csv[csv["maxtopic"] == topic_number].index)
    return prev_topic_grouping == automated_topic_grouping
