{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3a5fd58",
   "metadata": {},
   "source": [
    "# Single topic analysis\n",
    "\n",
    "New version, since script doesn't seem to work atm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f3fcb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Change in biggest topic overall's sentiment over time (per segment)\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter # count number of tweets\n",
    "\n",
    "import sentiment_segments # sentiment analysis functions\n",
    "\n",
    "NUM_SEGMENTS = 40 # decided on 40 segments for largest topic from ../BTM_topics/dataout/11_model_scores.csv\n",
    "\n",
    "# Input/output files\n",
    "BTM_SCORES_DATA_IN = \"../BTM_topics/dataout/\"\n",
    "BTM_DATA_IN_PREFIX = \"../datain/topic_modelling/\"\n",
    "BTM_DATA_OUT_PREFIX = \"../dataout/topic_modelling/\"\n",
    "\n",
    "SENTIMENT_DATA_IN_PREFIX = \"../datain/sentiment/\"\n",
    "SENTIMENT_DATA_OUT_PREFIX = \"../dataout/sentiment/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16318ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_modelling(topic_position, optimal_num_topics=11):\n",
    "    '''\n",
    "        Run topic modelling related functions.\n",
    "\n",
    "        Args:\n",
    "            topic_position: integer (0 for largest topic, 1 for second largest, etc.)\n",
    "            optimal_num_topics: optimal number of topics identified by the ElbowMethod (using the R BTM LogLik values)\n",
    "        Returns:\n",
    "            df: dataframe with topic numbers corresponding to their tweets.\n",
    "            selected_topic: the selected topic number\n",
    "    '''\n",
    "    df = load_data(optimal_num_topics)\n",
    "#     df = match_topic_with_tweet(df)\n",
    "#     selected_topic = get_selected_topic(df, topic_position)\n",
    "#     print(f\"\\tThe selected topic is: {selected_topic}\")\n",
    "#     plot_topic_distribution(df)\n",
    "#     export_topic_ids(df, selected_topic)\n",
    "#     cleaned_community_get_matching_topic_data(selected_topic)\n",
    "\n",
    "    return df\n",
    "#     return df, selected_topic\n",
    "\n",
    "\n",
    "# ******************************************************************************************\n",
    "# *** Topic modelling\n",
    "# ******************************************************************************************\n",
    "\n",
    "def load_data(optimal_num_topics=11):\n",
    "    '''\n",
    "        Get data.\n",
    "\n",
    "        Args:\n",
    "            optimal_num_topics: optimal number of topics identified by the ElbowMethod (using the R BTM LogLik values)\n",
    "        Returns\n",
    "            df: loaded BTM scores dataframe\n",
    "    '''\n",
    "    filename = BTM_SCORES_DATA_IN + f\"{optimal_num_topics}_model_scores.csv\"\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # change index to id\n",
    "    df = df.rename({'Unnamed: 0': 'id'}, axis=1) # rename column\n",
    "    df['id'] = df['id'].astype('int64')\n",
    "    df.set_index(\"id\", inplace = True)\n",
    "\n",
    "    # rename column headers to integer representations\n",
    "    for i in range(1, len(df.columns) + 1):\n",
    "        colname = \"V\" + str(i)\n",
    "        df = df.rename({colname: i}, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def match_topic_with_tweet(df):\n",
    "    '''\n",
    "        Get the topic that a tweet is most likely part of based on the \n",
    "        probablity that they're in the topic.\n",
    "\n",
    "        Args:\n",
    "            df: loaded BTM scores dataframe\n",
    "        Returns:\n",
    "            df: df with a column indicating their most probable topic\n",
    "    '''\n",
    "    maxtopic = df\n",
    "    # get the topic with the max probability value for each row\n",
    "    maxtopic = maxtopic.idxmax(axis=1) # ERROR\n",
    "    # convert all topics from string ('15') to int (15). This prerpares it for grouping by topic\n",
    "    maxtopic = maxtopic.astype(int)\n",
    "\n",
    "    # add maxtopic as a new column\n",
    "    df.insert(0, \"maxtopic\", maxtopic)\n",
    "\n",
    "    # sort by maxtopic\n",
    "    df = df.sort_values('maxtopic')\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0216970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying topic modelling & sentiment analysis on a single topic...\n",
      "\tTopic position: 0\n"
     ]
    }
   ],
   "source": [
    "# run\n",
    "topic_position=0\n",
    "optimal_num_topics=11\n",
    "\n",
    "print(f\"Applying topic modelling & sentiment analysis on a single topic...\")\n",
    "print(f\"\\tTopic position: {topic_position}\")\n",
    "# df, selected_topic = topic_modelling(topic_position, optimal_num_topics)\n",
    "df = topic_modelling(topic_position, optimal_num_topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f4919ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1399515966774530048</th>\n",
       "      <td>good project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399515957362450432</th>\n",
       "      <td>great project reset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399515936093204480</th>\n",
       "      <td>beautiful project congratulations whole team h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399515734007447552</th>\n",
       "      <td>participating cryptoultraman airdrop round</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399515723274280960</th>\n",
       "      <td>nice find project project great invite many pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356203583193063424</th>\n",
       "      <td>dena great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356197080272752640</th>\n",
       "      <td>join gays dena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356193045817872384</th>\n",
       "      <td>great project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356172769424244736</th>\n",
       "      <td>rates determined higher chance worse low chanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356089513857208320</th>\n",
       "      <td>friends</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407489 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         cleaned_tweet\n",
       "id                                                                    \n",
       "1399515966774530048                                       good project\n",
       "1399515957362450432                                great project reset\n",
       "1399515936093204480  beautiful project congratulations whole team h...\n",
       "1399515734007447552         participating cryptoultraman airdrop round\n",
       "1399515723274280960  nice find project project great invite many pe...\n",
       "...                                                                ...\n",
       "1356203583193063424                                         dena great\n",
       "1356197080272752640                                     join gays dena\n",
       "1356193045817872384                                      great project\n",
       "1356172769424244736  rates determined higher chance worse low chanc...\n",
       "1356089513857208320                                            friends\n",
       "\n",
       "[407489 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f6992",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxtopic = df\n",
    "# get the topic with the max probability value for each row\n",
    "maxtopic = maxtopic.idxmax(axis=1) # ERROR\n",
    "# convert all topics from string ('15') to int (15). This prerpares it for grouping by topic\n",
    "maxtopic = maxtopic.astype(int)\n",
    "\n",
    "# add maxtopic as a new column\n",
    "df.insert(0, \"maxtopic\", maxtopic)\n",
    "\n",
    "# sort by maxtopic\n",
    "df = df.sort_values('maxtopic')\n",
    "\n",
    "return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f2026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_topic(df, topic_position):\n",
    "    '''\n",
    "        Get the topic with the according to the topic_position that having the highest probability of being in that topic.\n",
    "            For example:\n",
    "                if topic_position is 0 it will get the topic with the most amount of tweets associated with it,\n",
    "                if topic_position is 1 it will get the topic with the second most amount of tweets associated with it,\n",
    "                etc.\n",
    "\n",
    "        Args:\n",
    "            df: df with a column indicating their most probable topic\n",
    "            topic_position: integer (0 for largest topic, 1 for second largest, etc.)\n",
    "        Returns:\n",
    "            selected_topic: the selected topic number\n",
    "    '''\n",
    "    # count the number of tweets per topic (and sort in descending order)\n",
    "    topic_counts = df['maxtopic'].value_counts()\n",
    "\n",
    "    # get max topic\n",
    "    selected_topic = topic_counts.index[topic_position]\n",
    "    return selected_topic\n",
    "\n",
    "def plot_topic_distribution(df):\n",
    "    '''\n",
    "        Plot the distribution of tweets associated with each topic.\n",
    "\n",
    "        Args:\n",
    "            df: df with a column indicating their most probable topic \n",
    "    '''\n",
    "    # filename = BTM_DATA_OUT_PREFIX + \"topic_distribution_overall.jpeg\"\n",
    "    filename = BTM_DATA_OUT_PREFIX + \"topic_distribution_overall.pdf\"\n",
    "    \n",
    "\n",
    "    # count the number of tweets per topic using Counter\n",
    "    topic2occurrences = Counter(df['maxtopic'])\n",
    "    ys = []\n",
    "    labels = []\n",
    "    for topic, occurrences in topic2occurrences.items():\n",
    "        labels.append(topic)\n",
    "        ys.append(occurrences)\n",
    "\n",
    "    plt.pie(ys, labels=labels)\n",
    "    plt.title('Ratio of tweets per topic')\n",
    "    # save graph\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "def export_topic_ids(df, selected_topic):\n",
    "    '''\n",
    "        Get topic tweet ids and export them to a csv file.\n",
    "\n",
    "        Args:\n",
    "            df: df with a column indicating their most probable topic\n",
    "            selected_topic: topic number who's IDs should be exported\n",
    "    '''\n",
    "    filename = SENTIMENT_DATA_IN_PREFIX + f\"ids_topic_{selected_topic}.csv\"\n",
    "    selected_topic_df = df.loc[df['maxtopic'] == selected_topic]\n",
    "\n",
    "    # export selected columns to csv\n",
    "    selected_columns = []\n",
    "    selected_topic_df.to_csv(filename, columns = selected_columns)\n",
    "\n",
    "def cleaned_community_get_matching_topic_data(selected_topic):\n",
    "    '''\n",
    "        Get the subset of the topic modelling data from the cleaned topic modelling data \n",
    "        (use the topic IDs to get the overal cleaned topic data matching those ids).\n",
    "\n",
    "        Args:\n",
    "            selected_topic: the topic number of the topic to be analysed.\n",
    "    '''\n",
    "    filename = \"../datain/topic_modelling/cleaned_tweets_largest_community.csv\" # overall tweets\n",
    "    # load cleaned btm tweet corpus data\n",
    "    cleaned_btm_df = pd.read_csv(filename)\n",
    "    cleaned_btm_df = cleaned_btm_df.drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "    # load topic ids\n",
    "    filename = SENTIMENT_DATA_IN_PREFIX + f\"ids_topic_{selected_topic}.csv\"\n",
    "    selected_topic_ids = pd.read_csv(filename)\n",
    "\n",
    "    # subset overall topic data with topic ids\n",
    "    selected_topic_btm_df = selected_topic_ids.merge(cleaned_btm_df, on='id', how='left')\n",
    "\n",
    "    # export selected topic to csv\n",
    "    filename = BTM_DATA_IN_PREFIX + f\"tweet_topic_subdf_topic_{selected_topic}.csv\"\n",
    "    selected_topic_btm_df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76d8f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91388f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8dc59a88",
   "metadata": {},
   "source": [
    "# sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb8aff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sentiment = sentiment_analysis(df, selected_topic)\n",
    "\n",
    "print(f\"\\tAverage sentiment for topic {selected_topic} is: {avg_sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa95768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******************************************************************************************\n",
    "# *** Sentiment analysis\n",
    "# ******************************************************************************************\n",
    "\n",
    "def sentiment_get_matching_topic_data(selected_topic):\n",
    "    '''\n",
    "        Get the subset of the topic modelling data from the cleaned sentiment data \n",
    "        (use the topic IDs to get the sentiment data matching those ids).\n",
    "\n",
    "        Args:\n",
    "            selected_topic: the topic number of the topic to be analysed.\n",
    "        Returns:\n",
    "            selected_topic_sentiment_df: subset of cleaned sentiment data that matches the selected topic's tweet ids.\n",
    "    '''\n",
    "    filename = SENTIMENT_DATA_IN_PREFIX + \"cleaned_tweets_for_sentiment.csv\"\n",
    "    # load cleaned tweet corpus data\n",
    "    cleaned_sentiment_df = pd.read_csv(filename)\n",
    "    cleaned_sentiment_df = cleaned_sentiment_df.drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "    # load topic ids\n",
    "    filename = SENTIMENT_DATA_IN_PREFIX + f\"ids_topic_{selected_topic}.csv\"\n",
    "    selected_topic_ids = pd.read_csv(filename)\n",
    "\n",
    "    # subset sentiment data with topic ids\n",
    "    selected_topic_sentiment_df = selected_topic_ids.merge(cleaned_sentiment_df, on='id', how='left')\n",
    "\n",
    "    # export selected topic sentiment to csv\n",
    "    filename = BTM_DATA_IN_PREFIX + f\"tweet_sentiment_subdf_topic_{selected_topic}.csv\"\n",
    "    selected_topic_sentiment_df.to_csv(filename)\n",
    "\n",
    "    return selected_topic_sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512affe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(df, selected_topic):\n",
    "    '''\n",
    "        Run sentiment analysis related functions.\n",
    "\n",
    "        Args:\n",
    "            df: dataframe with topic numbers corresponding to their tweets.\n",
    "            selected_topic: the topic number of the topic to be analysed.\n",
    "        Returns:\n",
    "            avg_sentiment: the average sentiment for the selected topic over the time period.\n",
    "    '''\n",
    "    print(\"\\tGetting topic sentiment...\")\n",
    "    # sentiment analysis\n",
    "    df = sentiment_get_matching_topic_data(selected_topic)\n",
    "    df = sentiment_segments.clean_sentiment_data(df)\n",
    "    # filename = SENTIMENT_DATA_OUT_PREFIX + f\"rounded_sentiment_topic_{selected_topic}.jpeg\"\n",
    "    filename = SENTIMENT_DATA_OUT_PREFIX + f\"rounded_sentiment_topic_{selected_topic}.pdf\"\n",
    "\n",
    "    df = sentiment_segments.sentiment_polarity_score(df, False, selected_topic, filename)\n",
    "    # segments\n",
    "    df, sub_dfs, num_segments = sentiment_segments.split_data_segments(df, NUM_SEGMENTS)\n",
    "    num_tweets_per_segment = round(len(sub_dfs[0]) / 1000, 1)\n",
    "    # filename = SENTIMENT_DATA_OUT_PREFIX + f\"sentiment_per_segment_topic_{selected_topic}.jpeg\"\n",
    "    filename = SENTIMENT_DATA_OUT_PREFIX + f\"sentiment_per_segment_topic_{selected_topic}.pdf\"\n",
    "    avg_sentiment = sentiment_segments.sentiment_per_segment(df, sub_dfs, num_segments, num_tweets_per_segment, False, selected_topic, filename)\n",
    "\n",
    "    return avg_sentiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
